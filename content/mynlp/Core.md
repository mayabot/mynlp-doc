---
title: "Core分词"
draft: false
---

## Core分词

Core实际上词典+二元语言模型+viterbi的一套成熟的、高效、分词歧义的基础分词算法。


```java
Lexers.core()
```
创建默认开启词性、人名识别的Lexer实例对象。



```java
Lexers.coreBuilder()
        .withPersonName()
        .withNer()
        .withPos()
        // ...
         .build();
```
通过Builder配置自定义的分析器实例。


### Lexer方法

```java
lexer.scan("文本")
```
![LexerMethod](images/lexer.png)


Consumer:
```java
lexer.scan("文本",(WordTerm word)->{
        ...
});
```
scan方法也可以传入对WordTerm的Consumer处理器。


### 词典资源

#### 格式

**核心词典格式：**

```text
龙舟节赛 1
龙舟赛 10
龙舟队 9
```

每行一个词和词频，**系统自带词典数量为22万+。**

**二元模型：**
```text
一一列举
	1 的
	3 出来
	5 了
一一年初
	1 我
一丁点
	1 痛苦 大 艰辛 力量 马虎 小 逆袭
	2 分离
	3 的
	4 散开
	12 儿
一丁点儿
	1 用途
```

这个是一个压缩文本格式，TAB缩进表示和主词的搭配关系，比如"一一列举"和"出来"在语料中搭配次数为3。
**系统自带的二元词典搭配数量为485万+**(Hanlp对应资源大概290万+)。

和Hanlp、ansj不同的是，核心词典中不涉及词性，所以对语料格式的要求只要求分词切分即可。
**Mynlp的词典训练语料规模为7000万+的语料库**


### 内存和性能

加载核心词典和二元语言模型，内存大小为50M。

在2.6 GHz Intel Core i7的Mac pro上，预热一遍后，对红楼梦文本2.6M文件进行测试。<br>

**耗时 392 ms， 速度 2286303字/秒**。

速度为228万字/秒


和其他分词器是对比是需要注意的是，上面的代码逻辑包含了对数字、英文、中文数字、量词、email、日期等固定模式的处理，
mynlp在固定模式规则上特有的处理方式给性能提供了绝对的保证。

